{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_datasets_preprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJrYtdKWz1wLbeiTUMuQtd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hshuai97/Colab20210803/blob/main/5_datasets_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "注意：使用Yao等人的数据集: [link](https://github.com/yao8839836/text_gcn)，并加以整理；其中，20ng使用的是cleaned之后的数据（corpus的数据数量不对），其他使用的是corpus中的原始数据"
      ],
      "metadata": {
        "id": "aGb_lg7mwig-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split  # for train and dev set split"
      ],
      "metadata": {
        "id": "7vVxcomnbgHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Split train and test set\n",
        "根据训练集和测试集的映射文件将训练数据train和测试数据test分开"
      ],
      "metadata": {
        "id": "yfLk0MsaONgR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFY9ufTySiPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c176da-7dce-4d5c-817f-6817320b9db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sample: 18846\n",
            "Total_mapping: 18846\n",
            "Time: 45.2457s\n",
            "==================================================\n",
            "Total sample: 7674\n",
            "Total_mapping: 7674\n",
            "Time: 55.0459s\n",
            "==================================================\n",
            "Total sample: 9100\n",
            "Total_mapping: 9100\n",
            "Time: 66.2946s\n",
            "==================================================\n",
            "Total sample: 7400\n",
            "Total_mapping: 7400\n",
            "Time: 86.5907s\n",
            "==================================================\n",
            "Total sample: 10662\n",
            "Total_mapping: 10662\n",
            "Time: 91.1435s\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def clean_text(NAME, text):\n",
        "    re_url = re.compile(r'(?:http|ftp|https)://(?:[\\w_-]+(?:(?:\\.[\\w_-]+)+))(?:[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')\n",
        "    re_email = re.compile('(?:[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])')\n",
        "    stop_words = stopwords.words('english')\n",
        "    # for 20ng\n",
        "    '''\n",
        "    text = re.sub(r'(From:\\s+[^\\n]+\\n)', '', text)\n",
        "    #text = re.sub(r'(Subject:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Organization:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Distribution:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Lines:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(([\\sA-Za-z0-9\\-]+)?[A|a]rchive-name:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Last-modified:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Version:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(NNTP-Posting-Host:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Nntp-Posting-Host:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(In article[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(In [^\\n]+writes:\\n)', '', text)\n",
        "    text = re.sub(r'(X-Newsreader:[^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(In-Reply-To: [^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Article-I.D.: [^\\n]+\\n)', '', text)\n",
        "    text = re.sub(r'(Expires: [^\\n]+\\n)', '', text)\n",
        "    '''\n",
        "    \n",
        "    # for 5 datasets\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = re.sub(re_url, '', text)\n",
        "    text = re.sub(re_email, '', text)\n",
        "\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "\n",
        "    text = re.sub(r\"[^A-Za-z().?!\\'\\`]\", \" \", text)\n",
        "    text = re.sub(r\"\\(\", \"\", text)\n",
        "    text = re.sub(r\"\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\'\", \"\", text)\n",
        "    text = re.sub(r'`', '', text)\n",
        "\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)  # Remove [ \\t\\n\\r\\f\\v].\n",
        "\n",
        "    # clean stopwords\n",
        "    if NAME in ['mr']:\n",
        "      return text\n",
        "    else:\n",
        "      text = [t for t in word_tokenize(text) if t not in stop_words]\n",
        "      text = ' '.join(text)\n",
        "\n",
        "      return text\n",
        "\n",
        "\n",
        "def Clean_and_Save(path, dataset_name):\n",
        "  NAME = dataset_name\n",
        "  if NAME not in ['20ng', 'r8', 'r52', 'oh', 'mr']:\n",
        "    raise ValueError('The dataset is not support')\n",
        "  raw_x = []\n",
        "  with open(os.path.join(path, NAME+'.txt'), encoding='latin1') as f:\n",
        "    data = f.readlines()\n",
        "    print(f'Total sample: {len(data)}')\n",
        "\n",
        "  with open(os.path.join(path, NAME+'_mapping.txt'), encoding='latin1') as f:\n",
        "    map = f.readlines()\n",
        "    print(f'Total_mapping: {len(map)}')\n",
        "\n",
        "  if len(map) != len(data):\n",
        "    raise Exception('map size not equal data')\n",
        "  \n",
        "  # clean sample and save\n",
        "  tes_x, tes_y = [], []\n",
        "  tra_x, tra_y = [], []\n",
        "  for i in range(len(map)):\n",
        "    clea = clean_text(NAME, data[i]).strip()\n",
        "    labe = map[i].split('\\t')\n",
        "\n",
        "    if labe[len(labe)-2] in ['20news-bydate-test', 'test']:\n",
        "      tes_x.append(clea)\n",
        "      tes_y.append(re.sub(r'\\n', '', labe[len(labe)-1]))\n",
        "    \n",
        "    elif labe[len(labe)-2] in ['20news-bydate-train', 'train', 'training']:\n",
        "      tra_x.append(clea)\n",
        "      tra_y.append(re.sub(r'\\n', '', labe[len(labe)-1]))\n",
        "    \n",
        "  if len(tes_y)!=len(tes_x) or len(tra_x)!=len(tra_y):\n",
        "    raise Exception('numbef of x is not equal y')\n",
        "\n",
        "  tra_res = list(zip(tra_y, tra_x))\n",
        "  random.shuffle(tra_res)\n",
        "  tra_y, tra_x = zip(*tra_res)\n",
        "\n",
        "  tes_res = list(zip(tes_y, tes_x))\n",
        "  random.shuffle(tes_res)\n",
        "  tes_y, tes_x = zip(*tes_res)\n",
        "\n",
        "  df_tra = pd.DataFrame({'tra_y': tra_y, 'tra_x': tra_x})\n",
        "  df_tes = pd.DataFrame({'tes_y': tes_y, 'tes_x': tes_x})\n",
        "\n",
        "  df_tra.columns = range(df_tra.shape[1])  # Remove the header\n",
        "  df_tes.columns = range(df_tes.shape[1])  # Remove the header\n",
        "\n",
        "\n",
        "  df_tra.to_csv(f'/content/drive/MyDrive/Colab_Notebooks/TextLevelGNN/data/{NAME}-stemmed.txt', index=False, sep='\\t',header=None)\n",
        "  df_tes.to_csv(f'/content/drive/MyDrive/Colab_Notebooks/TextLevelGNN/data/{NAME}-test-stemmed.txt', index=False, sep='\\t',header=None)\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab_Notebooks/TextLevelGNN/data/'\n",
        "\n",
        "t0 = time.time()\n",
        "for name in ['20ng', 'r8', 'r52', 'oh', 'mr']:\n",
        "  Clean_and_Save(path, name)\n",
        "  print(f'Time: {time.time() - t0:.4f}s')\n",
        "  print('='*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train and dev set"
      ],
      "metadata": {
        "id": "3cBHztjFwo6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 400})'''))\n",
        "\n",
        "def DataInfo_Divide(path, dataset_name):  # Statistic dataset information\n",
        "  NAME = dataset_name\n",
        "\n",
        "  y_stem = []\n",
        "  with open(os.path.join(path, NAME+'-stemmed.txt'), encoding='latin1') as f:\n",
        "    all = f.readlines()\n",
        "    for line in all:\n",
        "        t = line.split('\\t')\n",
        "        y_stem.append(t[0])\n",
        "  \n",
        "  # Statistic\n",
        "  target_names = list(set(y_stem))\n",
        "  print(f'Number of categories is {len(target_names)} in {NAME}-stemmed.txt')\n",
        "\n",
        "  # Split\n",
        "  if NAME in ['r52']:  # r52 some label only has 1\n",
        "    train, dev = train_test_split(all, test_size=0.1, shuffle=True, random_state=42)\n",
        "  else:\n",
        "    train, dev = train_test_split(all, test_size=0.1, shuffle=True, random_state=42, stratify=y_stem)\n",
        "\n",
        "  # Write new train and dev set\n",
        "  with open(os.path.join(path, NAME+'-train-stemmed.txt'), encoding='latin1', mode='w') as f:\n",
        "    f.write(''.join(train))\n",
        "  \n",
        "  with open(os.path.join(path, NAME+'-dev-stemmed.txt'), encoding='latin1', mode='w') as f:\n",
        "    f.write(''.join(dev))\n",
        "  \n",
        "\n",
        "\n",
        "  # Check\n",
        "  y_tra = []\n",
        "  with open(os.path.join(path, NAME+'-train-stemmed.txt'), encoding='latin1') as f:\n",
        "      tra = f.readlines()\n",
        "      for line in tra:\n",
        "        t = line.split('\\t')\n",
        "        y_tra.append(t[0])\n",
        "  \n",
        "  tar_nam = list(set(y_tra))  # Target names\n",
        "  index = pd.Index(y_tra)\n",
        "  print(f'Number of categories is {len(tar_nam)} in {NAME}-train-stemmed.txt,\\n{index.value_counts()}')\n",
        "\n",
        "\n",
        "  y_dev = []\n",
        "  with open(os.path.join(path, NAME+'-dev-stemmed.txt'), encoding='latin1') as f:\n",
        "      de = f.readlines()\n",
        "      for line in de:\n",
        "        t = line.split('\\t')\n",
        "        y_dev.append(t[0])\n",
        "  tar_nam_ = list(set(y_dev))  # target names\n",
        "  print(f'Number of categories is {len(tar_nam_)} in {NAME}-dev-stemmed.txt')\n",
        "  print(f'\\nNew total train: {len(tra)+len(de)}, new train: {len(tra)}, new dev: {len(de)}')\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab_Notebooks/TextLevelGNN/data/'\n",
        "\n",
        "t1 = time.time()\n",
        "for name in ['20ng', 'r8', 'r52', 'oh', 'mr']:\n",
        "  DataInfo_Divide(path, name)\n",
        "  print(f'Time: {time.time() - t1:.4f}s')\n",
        "  print('='*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "a8_kMvlmJv77",
        "outputId": "96d67e7a-d9d8-4d0b-dd7d-a8cc836738f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories is 20 in 20ng-stemmed.txt\n",
            "Number of categories is 20 in 20ng-train-stemmed.txt,\n",
            "rec.sport.hockey            540\n",
            "soc.religion.christian      539\n",
            "rec.motorcycles             538\n",
            "rec.sport.baseball          537\n",
            "sci.crypt                   535\n",
            "rec.autos                   535\n",
            "sci.med                     535\n",
            "comp.windows.x              534\n",
            "sci.space                   534\n",
            "sci.electronics             532\n",
            "comp.os.ms-windows.misc     532\n",
            "comp.sys.ibm.pc.hardware    531\n",
            "comp.graphics               526\n",
            "misc.forsale                526\n",
            "comp.sys.mac.hardware       520\n",
            "talk.politics.mideast       508\n",
            "talk.politics.guns          491\n",
            "alt.atheism                 432\n",
            "talk.politics.misc          418\n",
            "talk.religion.misc          339\n",
            "dtype: int64\n",
            "Number of categories is 20 in 20ng-dev-stemmed.txt\n",
            "\n",
            "New total train: 11314, new train: 10182, new dev: 1132\n",
            "Time: 1.0253s\n",
            "==================================================\n",
            "Number of categories is 8 in r8-stemmed.txt\n",
            "Number of categories is 8 in r8-train-stemmed.txt,\n",
            "earn        2556\n",
            "acq         1436\n",
            "crude        228\n",
            "trade        226\n",
            "money-fx     185\n",
            "interest     171\n",
            "ship          97\n",
            "grain         37\n",
            "dtype: int64\n",
            "Number of categories is 8 in r8-dev-stemmed.txt\n",
            "\n",
            "New total train: 5485, new train: 4936, new dev: 549\n",
            "Time: 1.5491s\n",
            "==================================================\n",
            "Number of categories is 52 in r52-stemmed.txt\n",
            "Number of categories is 52 in r52-train-stemmed.txt,\n",
            "earn               2545\n",
            "acq                1443\n",
            "trade               231\n",
            "crude               221\n",
            "money-fx            187\n",
            "interest            170\n",
            "money-supply        108\n",
            "ship                100\n",
            "sugar                85\n",
            "coffee               84\n",
            "gold                 63\n",
            "gnp                  53\n",
            "cpi                  46\n",
            "cocoa                42\n",
            "reserves             35\n",
            "grain                35\n",
            "jobs                 33\n",
            "ipi                  30\n",
            "copper               30\n",
            "alum                 28\n",
            "rubber               28\n",
            "iron-steel           25\n",
            "nat-gas              23\n",
            "bop                  20\n",
            "veg-oil              17\n",
            "retail               17\n",
            "cotton               15\n",
            "housing              14\n",
            "livestock            13\n",
            "tin                  13\n",
            "orange               12\n",
            "wpi                  11\n",
            "pet-chem             11\n",
            "lei                  10\n",
            "gas                   9\n",
            "strategic-metal       9\n",
            "zinc                  8\n",
            "lumber                6\n",
            "income                6\n",
            "meal-feed             5\n",
            "carcass               5\n",
            "heat                  5\n",
            "lead                  4\n",
            "instal-debt           4\n",
            "fuel                  4\n",
            "dlr                   3\n",
            "cpu                   3\n",
            "tea                   2\n",
            "nickel                2\n",
            "potato                2\n",
            "jet                   2\n",
            "platinum              1\n",
            "dtype: int64\n",
            "Number of categories is 40 in r52-dev-stemmed.txt\n",
            "\n",
            "New total train: 6532, new train: 5878, new dev: 654\n",
            "Time: 2.2621s\n",
            "==================================================\n",
            "Number of categories is 23 in oh-stemmed.txt\n",
            "Number of categories is 23 in oh-train-stemmed.txt,\n",
            "C14    526\n",
            "C04    387\n",
            "C23    339\n",
            "C21    216\n",
            "C10    193\n",
            "C20    161\n",
            "C06    158\n",
            "C18    151\n",
            "C12    139\n",
            "C08    109\n",
            "C01    103\n",
            "C17     91\n",
            "C13     83\n",
            "C05     75\n",
            "C16     53\n",
            "C15     49\n",
            "C11     44\n",
            "C19     36\n",
            "C09     32\n",
            "C07     26\n",
            "C02     23\n",
            "C03     19\n",
            "C22      8\n",
            "dtype: int64\n",
            "Number of categories is 23 in oh-dev-stemmed.txt\n",
            "\n",
            "New total train: 3357, new train: 3021, new dev: 336\n",
            "Time: 2.6301s\n",
            "==================================================\n",
            "Number of categories is 2 in mr-stemmed.txt\n",
            "Number of categories is 2 in mr-train-stemmed.txt,\n",
            "1    3199\n",
            "0    3198\n",
            "dtype: int64\n",
            "Number of categories is 2 in mr-dev-stemmed.txt\n",
            "\n",
            "New total train: 7108, new train: 6397, new dev: 711\n",
            "Time: 2.6895s\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'wow, you are so smart.'\n",
        "\n",
        "#text = re.sub(r',', '.', text)\n",
        "res = sent_tokenize(text)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0HjXCtti0gy",
        "outputId": "ce5b5902-b040-411a-ce8b-7b7ca5851c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow, you are so smart.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}